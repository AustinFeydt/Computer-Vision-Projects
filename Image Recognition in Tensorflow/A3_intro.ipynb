{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Austin Feydt (apf31)\n",
    "\n",
    "March 30 2018\n",
    "\n",
    "EECS 531: Assignment 3\n",
    "\n",
    "# Data Collection And Preprocessing\n",
    "\n",
    "The most interesting part of my assignment is my data collection method.  As a background, the data I'm using is based on a part of my thesis, dealing with 3D object recognition for a robot.  As an interesting twist on my thesis, I actually collect all of my data completely in a computer simulation, rather than in real life.  This allows me to automate the data collection process and generate large volumes of data.  My hopes are that, once trained, my neural nets will be able to work on real-world data.\n",
    "\n",
    "The data collection process is broken down into a few different steps:\n",
    "\n",
    "1) I downloaded CAD objects off the internet (grabcad.com) and extract their mesh to spawn physical objects in Gazebo (a physics simulator).  I drop the objects on a table, and take a picture of them using a Kinect:\n",
    "<img src=\"A3_images/sim.png\" width=\"400\">\n",
    "\n",
    "2) The image taken by the Kinect is not just a plain png or jpeg, but a 3D pointcloud image, which is a collection of points in 3D space, representing density of matter:\n",
    "<img src=\"A3_images/pcl.png\" width=\"400\">\n",
    "\n",
    "3) The pointcloud image must be converted to a png to be useful in classification.  So, I used an external library called pcl2png, which does exactly what you might think: it converts pointclouds to pngs by projecting the image into 2D space:\n",
    "<img src=\"A3_images/wheel_1.png\" width=\"400\">\n",
    "\n",
    "4) The last step of pre-processing involves smoothing and cropping the image to a much smaller dimension, and also converting it to a jpeg file.  This will speed up network training, as our dimensions will only be about 64x64 for the first layer of convolutions:\n",
    "<img src=\"A3_images/class_9_index_8.jpeg\" width=\"400\">\n",
    "\n",
    "\n",
    "\n",
    "# Creating .tfrecords For Training\n",
    "\n",
    "Once the data was all collected and processed, I compiled it all into some tfrecords, which serialize all of the jpegs and maintain each object's label as well.  This makes the network much more portable, as the tfrecords are *significantly* smaller than folders of jpegs, and also makes it convenient to load the data into tensorflow, as all of the labels and dimensions of the images are maintained. I've omitted the code, as it's 300 lines and not necessarily important to the project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
