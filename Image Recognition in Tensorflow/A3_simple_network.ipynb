{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Austin Feydt (apf31)\n",
    "\n",
    "March 30 2018\n",
    "\n",
    "EECS 531: Assignment 3\n",
    "\n",
    "# Simple Network\n",
    "\n",
    "I began by constructing a very simple neural network as a baseline.  This network flattens the image to a 1 dimensional vector, and then has a fully connected layer, which condenses the network from 64x64x3 nodes in the input layer to just 128 nodes in the hidden layer (with the rectified linear unit as an activation function). Then, the hidden layer is fully connected to the output layer, which is just 3 nodes, representing the 3 labels. The network chooses the largest output as the predicted label of the input object. \n",
    "\n",
    "Below, we can see the implementation of this simple network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "DATA_DIR = \"data/\"\n",
    "TRAINING_SET_SIZE = 13718\n",
    "BATCH_SIZE = 16\n",
    "IMAGE_SIZE = 64\n",
    "CHANNELS = 3\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "class _image_object:\n",
    "    def __init__(self):\n",
    "        self.image = tf.Variable([], dtype = tf.string)\n",
    "        self.height = tf.Variable([], dtype = tf.int64)\n",
    "        self.width = tf.Variable([], dtype = tf.int64)\n",
    "        self.filename = tf.Variable([], dtype = tf.string)\n",
    "        self.label = tf.Variable([], dtype = tf.int32)\n",
    "\n",
    "def read_and_decode(filename_queue):\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(serialized_example, features = {\n",
    "        \"image/encoded\": tf.FixedLenFeature([], tf.string),\n",
    "        \"image/height\": tf.FixedLenFeature([], tf.int64),\n",
    "        \"image/width\": tf.FixedLenFeature([], tf.int64),\n",
    "        \"image/filename\": tf.FixedLenFeature([], tf.string),\n",
    "        \"image/class/label\": tf.FixedLenFeature([], tf.int64),})\n",
    "    image_encoded = features[\"image/encoded\"]\n",
    "    image_raw = tf.image.decode_jpeg(image_encoded, channels=CHANNELS)\n",
    "    print(image_raw)\n",
    "    image_object = _image_object()\n",
    "    image_object.image = tf.image.resize_image_with_crop_or_pad(image_raw, IMAGE_SIZE, IMAGE_SIZE)\n",
    "    image_object.height = features[\"image/height\"]\n",
    "    image_object.width = features[\"image/width\"]\n",
    "    image_object.filename = features[\"image/filename\"]\n",
    "    image_object.label = tf.cast(features[\"image/class/label\"], tf.int64)\n",
    "    return image_object\n",
    "\n",
    "def net_input(if_random = True, if_training = True):\n",
    "    if(if_training):\n",
    "        filenames = [os.path.join(DATA_DIR, \"train-0000%d-of-00002.tfrecord\" % i) for i in range(0, 1)]\n",
    "    else:\n",
    "        filenames = [os.path.join(DATA_DIR, \"validation-0000%d-of-00002.tfrecord\" % i) for i in range(0, 1)]\n",
    "\n",
    "    for f in filenames:\n",
    "        if not tf.gfile.Exists(f):\n",
    "            raise ValueError(\"Failed to find file: \" + f)\n",
    "    filename_queue = tf.train.string_input_producer(filenames)\n",
    "    image_object = read_and_decode(filename_queue)\n",
    "    image = tf.image.per_image_standardization(image_object.image)\n",
    "    label = image_object.label\n",
    "    filename = image_object.filename\n",
    "\n",
    "    image_batch, label_batch, filename_batch = tf.train.batch([image, label, filename],batch_size = BATCH_SIZE,num_threads = 1)\n",
    "    return image_batch, label_batch, filename_batch\n",
    "\n",
    "\n",
    "def weight_variable(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "\n",
    "def bias_variable(val,shape):\n",
    "    if val == 0:\n",
    "        return tf.Variable(tf.zeros(shape))\n",
    "    else:\n",
    "        return tf.Variable(tf.constant(val, shape=shape))\n",
    "\n",
    "def conv2d(x, W, padding):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=padding)\n",
    "\n",
    "def max_pool_2x2(x, kernel_size):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1,2,2,1], padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplenet_inference(image_batch):\n",
    "    depth1 = 128\n",
    "    depth2 = 3\n",
    "\n",
    "    x_image = tf.reshape(image_batch, [BATCH_SIZE, IMAGE_SIZE*IMAGE_SIZE*CHANNELS])\n",
    "    \n",
    "    print(x_image.shape)\n",
    "\n",
    "    # Start by defining all variables\n",
    "    W_1 = weight_variable([IMAGE_SIZE*IMAGE_SIZE*CHANNELS, depth1])\n",
    "    b_1 = bias_variable(0, [depth1])\n",
    "    \n",
    "    W_2 = weight_variable([depth1, depth2])\n",
    "    b_2 = bias_variable(0, [depth2])\n",
    "\n",
    "    # First fully connected layer\n",
    "    hidden = tf.nn.relu(tf.matmul(x_image, W_1) + b_1)\n",
    "\n",
    "    #Fully connected layers leading to logits\n",
    "    output = tf.matmul(hidden,W_2) + b_2\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "def simple_train():\n",
    "    image_batch_out, label_batch_out, filename_batch = net_input(if_random = False, if_training = True)\n",
    "\n",
    "    image_batch_placeholder = tf.placeholder(tf.float32, shape=[BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS])\n",
    "    image_batch = tf.reshape(image_batch_out, (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS))\n",
    "\n",
    "    label_batch_placeholder = tf.placeholder(tf.float32, shape=[BATCH_SIZE, 3])\n",
    "    label_offset = -tf.ones([BATCH_SIZE], dtype=tf.int64, name=\"label_batch_offset\")\n",
    "    label_batch_one_hot = tf.one_hot(tf.add(label_batch_out, label_offset), depth=3, on_value=1.0, off_value=0.0)\n",
    "\n",
    "\n",
    "    logits_out = simplenet_inference(image_batch_placeholder)\n",
    "    loss = tf.losses.mean_squared_error(labels=label_batch_placeholder, predictions=logits_out)\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.00005).minimize(loss)\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        file_writer = tf.summary.FileWriter(\"./logs\", sess.graph)\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver.restore(sess, \"simpleoutput/checkpoint-train\")\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord, sess = sess)\n",
    "\n",
    "        for i in range(10000):\n",
    "            image_out, label_out, label_batch_one_hot_out, filename_out = sess.run([image_batch, label_batch_out, label_batch_one_hot, filename_batch])\n",
    "            _, infer_out, loss_out = sess.run([train_step, logits_out, loss], feed_dict={image_batch_placeholder: image_out, label_batch_placeholder: label_batch_one_hot_out})\n",
    "          \n",
    "            if(i%25 == 0):\n",
    "                print(loss_out)\n",
    "                saver.save(sess, \"simpleoutput/checkpoint-train\")\n",
    "\n",
    "            if(loss_out < 0.02):\n",
    "            \tbreak\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        sess.close()\n",
    "\n",
    "#simple_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"DecodeJpeg:0\", shape=(?, ?, 3), dtype=uint8)\n",
      "(16, 12288)\n",
      "WARNING:tensorflow:From <ipython-input-3-7e54db8ffa54>:13: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "INFO:tensorflow:Restoring parameters from simpleoutput/checkpoint-train\n",
      "real labels:\n",
      "[2 0 0 0 2 2 2 2 1 2 1 2 0 1 0 2]\n",
      "predicted labels:\n",
      "[2 0 0 0 2 2 2 2 2 2 2 2 0 2 0 2]\n",
      "\n",
      "real labels:\n",
      "[0 1 0 2 2 2 1 0 2 0 1 0 1 0 1 2]\n",
      "predicted labels:\n",
      "[0 2 0 2 2 2 2 0 2 2 2 0 2 0 2 2]\n",
      "\n",
      "real labels:\n",
      "[1 0 0 0 0 2 1 0 0 0 2 2 2 0 1 2]\n",
      "predicted labels:\n",
      "[2 0 0 0 0 2 2 0 0 0 2 2 2 0 2 2]\n",
      "\n",
      "real labels:\n",
      "[1 1 2 1 2 1 0 0 0 2 1 2 2 2 0 1]\n",
      "predicted labels:\n",
      "[2 2 2 2 2 2 0 0 0 2 2 2 2 2 0 2]\n",
      "\n",
      "real labels:\n",
      "[1 0 0 1 0 2 1 2 0 1 1 1 0 2 2 2]\n",
      "predicted labels:\n",
      "[2 0 0 2 0 2 2 2 0 2 2 2 0 2 2 2]\n",
      "\n",
      "Accuracy: \n",
      "0.66875\n"
     ]
    }
   ],
   "source": [
    "def simple_evaluate():\n",
    "    image_batch_out, label_batch_out, filename_batch = net_input(if_random = False, if_training = False)\n",
    "\n",
    "    image_batch_placeholder = tf.placeholder(tf.float32, shape=[BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS])\n",
    "    image_batch = tf.reshape(image_batch_out, (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS))\n",
    "\n",
    "    label_tensor_placeholder = tf.placeholder(tf.int64, shape=[BATCH_SIZE])\n",
    "    label_offset = -tf.ones([BATCH_SIZE], dtype=tf.int64, name=\"label_batch_offset\")\n",
    "    label_batch = tf.add(label_batch_out, label_offset)\n",
    "\n",
    "    logits_out = tf.reshape(simplenet_inference(image_batch_placeholder), [BATCH_SIZE, 3])\n",
    "    logits_batch = tf.to_int64(tf.arg_max(logits_out, dimension = 1))\n",
    "\n",
    "    correct_prediction = tf.equal(logits_batch, label_tensor_placeholder)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver.restore(sess,  \"simpleoutput/checkpoint-train\")\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord, sess = sess)\n",
    "\n",
    "        accuracy_accu = 0\n",
    "\n",
    "        for i in range(50):\n",
    "            image_out, label_out, filename_out = sess.run([image_batch, label_batch, filename_batch])\n",
    "\n",
    "            accuracy_out, logits_batch_out = sess.run([accuracy, logits_batch], feed_dict={image_batch_placeholder: image_out, label_tensor_placeholder: label_out})\n",
    "            accuracy_accu += accuracy_out\n",
    "            if i % 10 == 0: \n",
    "                print('real labels:')\n",
    "                print(label_out)\n",
    "                print('predicted labels:')\n",
    "                print(logits_batch_out)\n",
    "                print('')\n",
    "    \n",
    "        print(\"Accuracy: \")\n",
    "        print(accuracy_accu / 50)\n",
    "\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        sess.close()\n",
    "\n",
    "simple_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "From above, we can see that the accuracy is only around 67%, which is not much better than a random classifier.  This is mainly because of the structure of the network.  We know that there is almost always an underlying structure to the pixels in an image.  However, this network strings the entire image out into a single line of pixels, getting rid of any structure whatsoever.  Thus, the network is just attempting to predict the output based on a sequence of 12,288 pixel values, with no knowledge of the previous spacial features of the image. We will next construct a convolutional neural network, which will take advantage of the structure of the input images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
